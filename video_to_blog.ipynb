{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import cv2\n",
    "import json\n",
    "import base64\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from typing import Union\n",
    "import concurrent.futures\n",
    "from pytube import YouTube\n",
    "from moviepy.editor import VideoFileClip\n",
    "from pytube.exceptions import PytubeError\n",
    "\n",
    "from openai import OpenAI\n",
    "client = OpenAI(api_key='sk-')\n",
    "\n",
    "def download_youtube_video(video_url: str) -> str:\n",
    "    \"\"\"\n",
    "    Downloads the highest resolution video from a given YouTube URL.\n",
    "\n",
    "    Args:\n",
    "        video_url (str): The URL of the YouTube video to download.\n",
    "\n",
    "    Returns:\n",
    "        str: The filename of the downloaded video.\n",
    "\n",
    "    Raises:\n",
    "        RuntimeError: If an error occurs during the download.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        youtube = YouTube(video_url)\n",
    "        stream = youtube.streams.get_highest_resolution()\n",
    "        filename = f\"{youtube.title}.mp4\".replace('/', '_').replace('\\\\', '_')\n",
    "        stream.download(filename=filename)\n",
    "        return filename\n",
    "    except PytubeError as e:\n",
    "        raise RuntimeError(\n",
    "            f\"An error occurred while downloading the video: {e}\")\n",
    "\n",
    "\n",
    "def extract_audio_from_video(video_file_path: str) -> str:\n",
    "    \"\"\"\n",
    "    Extracts the audio from a video file and saves it as an MP3.\n",
    "\n",
    "    Args:\n",
    "        video_file_path (str): The file path of the video file to extract audio from.\n",
    "\n",
    "    Returns:\n",
    "        str: The filename of the saved MP3 audio file.\n",
    "\n",
    "    Raises:\n",
    "        RuntimeError: If an error occurs during the audio extraction.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        video_clip = VideoFileClip(video_file_path)\n",
    "        audio_clip = video_clip.audio\n",
    "        head, tail = os.path.split(video_file_path)\n",
    "        file_name, _ = os.path.splitext(tail)\n",
    "        mp3_filename = f\"{file_name}.mp3\"\n",
    "        audio_clip.write_audiofile(mp3_filename, logger=None)\n",
    "        audio_clip.close()\n",
    "        video_clip.close()\n",
    "        return mp3_filename\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"An error occurred while extracting audio: {e}\")\n",
    "\n",
    "\n",
    "def extract_frames_from_video(video_path: str, output_folder: str, time_interval: int):\n",
    "    \"\"\"\n",
    "    Extracts individual frames from a video at a specific time interval and provides the paths to these images in ascending order.\n",
    "\n",
    "    Args:\n",
    "        - video_path (str): The path to the video file.\n",
    "        - output_folder (str): The directory where the extracted frames should be saved.\n",
    "        - time_interval (int): The time interval in seconds at which to extract frames.\n",
    "\n",
    "    Returns:\n",
    "        - A list of the saved image file paths.\n",
    "\n",
    "    Raises:\n",
    "        - ValueError: If the video cannot be opened.\n",
    "        - RuntimeError: If an error occurs during frame extraction.\n",
    "    \"\"\"\n",
    "    video_capture = None\n",
    "    image_paths = []\n",
    "\n",
    "    try:\n",
    "        video_capture = cv2.VideoCapture(video_path)\n",
    "        if not video_capture.isOpened():\n",
    "            raise ValueError(\"Could not open video.\")\n",
    "\n",
    "        total_frames = int(video_capture.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        fps = video_capture.get(cv2.CAP_PROP_FPS)\n",
    "        duration_seconds = total_frames / fps\n",
    "\n",
    "        if not os.path.exists(output_folder):\n",
    "            os.makedirs(output_folder)\n",
    "\n",
    "        current_time = 0\n",
    "        while current_time <= duration_seconds:\n",
    "            frame_number = int(fps * current_time)\n",
    "            if frame_number >= total_frames:\n",
    "                break\n",
    "\n",
    "            video_capture.set(cv2.CAP_PROP_POS_FRAMES, frame_number)\n",
    "            success, frame = video_capture.read()\n",
    "            if not success:\n",
    "                current_time += time_interval\n",
    "                continue\n",
    "\n",
    "            output_image_path = os.path.join(\n",
    "                output_folder, f'{current_time:04d}.jpg')\n",
    "            cv2.imwrite(output_image_path, frame)\n",
    "            image_paths.append(output_image_path)\n",
    "            current_time += time_interval\n",
    "\n",
    "        return image_paths\n",
    "\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"An error occurred while extracting frames: {e}\")\n",
    "    finally:\n",
    "        if video_capture:\n",
    "            video_capture.release()\n",
    "\n",
    "\n",
    "def transcribe_audio(audio_file_path: str, segment_len: int = 0, segment_start: int = 0) -> Union[str, list[str]]:\n",
    "    \"\"\"\n",
    "    Transcribes the given audio file and optionally segments the transcription with timestamps.\n",
    "\n",
    "    Args:\n",
    "        audio_file_path (str): The file path of the audio file to transcribe.\n",
    "        segment_len (int): The length of each segment in seconds for timestamping. If 0, no segmentation is done.\n",
    "        segment_start (int): The start time in seconds for the first segment.\n",
    "\n",
    "    Returns:\n",
    "        Union[str, List[str]]: The transcribed text as a string if segment_len is zero, or a list of timestamped segments as strings if segment_len is not zero.\n",
    "    \"\"\"\n",
    "    # Assuming `client` is a pre-defined global variable or imported module with the `audio.transcriptions.create` method.\n",
    "    with open(audio_file_path, \"rb\") as audio_file:\n",
    "        transcript = client.audio.transcriptions.create(\n",
    "            file=audio_file,\n",
    "            model=\"whisper-1\",\n",
    "            response_format=\"verbose_json\",\n",
    "            timestamp_granularities=[\"segment\"],\n",
    "        )\n",
    "\n",
    "    # If segment_len is zero, return the transcript as a string.\n",
    "    if segment_len == 0:\n",
    "        return transcript.text\n",
    "\n",
    "    # Transcript is a Pydantic model, thus converting it to a dictionary\n",
    "    transcript = transcript.model_dump()\n",
    "\n",
    "    # Helper function to format timestamps.\n",
    "    def format_timestamp(seconds: int) -> str:\n",
    "        hours, remainder = divmod(seconds, 3600)\n",
    "        minutes, seconds = divmod(remainder, 60)\n",
    "        return f\"{hours:02}:{minutes:02}:{seconds:02}\"\n",
    "\n",
    "    # Initialize variables for processing segments.\n",
    "    segment_text = \"\"\n",
    "    formatted_transcript = []\n",
    "\n",
    "    # Assuming the transcript is a dictionary with a 'segments' key that contains a list of segment dictionaries.\n",
    "    segments = transcript.get('segments', [])\n",
    "\n",
    "    for segment in segments:\n",
    "        start_time = segment.get('start')\n",
    "        end_time = segment.get('end')\n",
    "        text = segment.get('text').strip()\n",
    "\n",
    "        if segment_text and (start_time - segment_start >= segment_len or segment is segments[-1]):\n",
    "            formatted_segment = f\"{format_timestamp(segment_start)} - {format_timestamp(segment_start + segment_len)} {segment_text}\"\n",
    "            formatted_transcript.append(formatted_segment)\n",
    "            segment_start += segment_len\n",
    "            segment_text = text\n",
    "        else:\n",
    "            segment_text += \" \" + text\n",
    "\n",
    "        while start_time - segment_start >= segment_len:\n",
    "            segment_start += segment_len\n",
    "\n",
    "    # Add the last segment if there is any text left.\n",
    "    if segment_text:\n",
    "        formatted_segment = f\"{format_timestamp(segment_start)} - {format_timestamp(segment_start + (segment_len if segment_start + segment_len <= end_time else end_time))} {segment_text.strip()}\"\n",
    "        formatted_transcript.append(formatted_segment)\n",
    "\n",
    "    return formatted_transcript\n",
    "\n",
    "\n",
    "def create_prompt(encoded_images: list[str], prompt_template: str):\n",
    "    \"\"\"\n",
    "    Combines Prompt String with Multiple Images to create message array \n",
    "    To be Passed to GPT Vision model\n",
    "\n",
    "    Parameters:\n",
    "    - encoded_images:\n",
    "    - prompt_template:\n",
    "\n",
    "    Returns:\n",
    "    - messages:\n",
    "    \"\"\"\n",
    "    messages = [{\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"text\", \"text\": prompt_template}\n",
    "        ] + [\n",
    "            {\n",
    "                \"type\": \"image_url\",\n",
    "                \"image_url\": {\n",
    "                    \"url\": f\"data:image/jpeg;base64,{base64_image}\",\n",
    "                    \"detail\": \"high\"\n",
    "                }\n",
    "            } for base64_image in encoded_images\n",
    "        ]\n",
    "    }]\n",
    "    return messages\n",
    "\n",
    "\n",
    "def convert_images_to_base64(image_data_list: list[bytes]) -> list[str]:\n",
    "    \"\"\"\n",
    "    Converts a list of image data to a list of Base64 encoded images.\n",
    "\n",
    "    Parameters:\n",
    "    - image_data_list: List of bytes objects containing image data.\n",
    "\n",
    "    Returns:\n",
    "    - List of Base64 encoded strings representing each image.\n",
    "    \"\"\"\n",
    "    encoded_images = []\n",
    "\n",
    "    for image_data in image_data_list:\n",
    "        # Open the image from bytes data\n",
    "        image = Image.open(BytesIO(image_data))\n",
    "\n",
    "        # Convert the PIL image to a byte stream\n",
    "        img_byte_arr = BytesIO()\n",
    "        image.save(img_byte_arr, format='JPEG')\n",
    "\n",
    "        # Encode the image to Base64 and convert bytes to string\n",
    "        encoded_img_str = base64.b64encode(\n",
    "            img_byte_arr.getvalue()).decode('utf-8')\n",
    "\n",
    "        encoded_images.append(encoded_img_str)\n",
    "\n",
    "    return encoded_images\n",
    "\n",
    "\n",
    "#######################################\n",
    "\n",
    "\n",
    "def extract_json_from_response(model_response: str) -> str:\n",
    "    \"\"\"\n",
    "    Extract JSON from OpenAI Responce\n",
    "    \"\"\"\n",
    "    PATTERN_JSON_BLOCK = r\"```json\\n(.*?)\\n```\"\n",
    "\n",
    "    json_blocks = re.findall(\n",
    "        PATTERN_JSON_BLOCK, model_response, re.DOTALL\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        extracted_json = json_blocks[0]\n",
    "    except IndexError:\n",
    "        raise ValueError(\"JSON not found in model response\")\n",
    "\n",
    "    return extracted_json\n",
    "\n",
    "\n",
    "def format_duration(seconds):\n",
    "    \"\"\"\n",
    "    Formats the duration from seconds to a string of the form \"XX hrs XX minutes and XX seconds long\".\n",
    "    If the duration is less than a minute, it returns \"XX seconds long\".\n",
    "\n",
    "    :param seconds: The duration of the video in seconds.\n",
    "    :return: A formatted string representing the duration.\n",
    "    \"\"\"\n",
    "    if seconds >= 3600:  # More than 1 hour\n",
    "        hours = seconds // 3600\n",
    "        minutes = (seconds % 3600) // 60\n",
    "        seconds = seconds % 60\n",
    "        return f\"{hours} hrs {minutes} minutes and {seconds} seconds\"\n",
    "    elif seconds >= 60:  # More than 1 minute\n",
    "        minutes = seconds // 60\n",
    "        seconds = seconds % 60\n",
    "        return f\"{minutes} minutes and {seconds} seconds\"\n",
    "    else:  # Less than 1 minute\n",
    "        return f\"{seconds} seconds\"\n",
    "\n",
    "\n",
    "def get_segment_timestamp(segment_string):\n",
    "    timestamp_pattern = r'\\d{2}:\\d{2}:\\d{2} - \\d{2}:\\d{2}:\\d{2}'\n",
    "    match = re.search(timestamp_pattern, segment_string)\n",
    "\n",
    "    if match:\n",
    "        transcript_timestamp = match.group()\n",
    "    else:\n",
    "        transcript_timestamp = \"\"\n",
    "\n",
    "    return transcript_timestamp\n",
    "\n",
    "\n",
    "PROMPT_TEMPLATE = \"\"\"Your task is to write segments of professional blog/article complete with relevant links, code and Images, based on a YouTube video titled \"{video_title}\".\n",
    "\n",
    "Attached are five images sequentially, extracted from **{segment_len}** second segment of a video.  \n",
    "\n",
    "The images paths are:\n",
    "```\n",
    "{image_paths}\n",
    "```\n",
    "\n",
    "These images are numbered as the time in seconds from the beginning of the video (dot) jpg. \n",
    "The complete video duration is **{video_length}**\n",
    "\n",
    "Below is the transcript between time: {timestamp} of the video:\n",
    "```\n",
    "{transcript_segment}\n",
    "```\n",
    "\n",
    "Your final aim is to extract USEFUL INFORMATION in DETAIL from the images that closely relates with the video transcription.\n",
    "The information that you will extract, will be used to create a professional article/tutorial/blog from the video. \n",
    "\n",
    "Based on the images and the transcript, for each image output the following JSON:\n",
    "{json_template}\n",
    "\n",
    "**IMPORTANT:**\n",
    "- Make sure that in the Summary, you should include **ALL** the text and properly formatted **code** from the image\n",
    "- Note that the `summary` of relevent images will be used to create the final blog.\n",
    "- Output **JSON**\n",
    "\n",
    "Take a DEEP breath and Think Step By Step.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "JSON_TEMPLATE = \"\"\"```json\n",
    "[\n",
    "    {{\n",
    "        \"image_path\": \"name/path of the image. Note: The name is the time in seconds at which the frame was captured from the video\",\n",
    "        \"summary\": \"**A DETAILED Summary of the image for the blog**, including relevant Content from the image frame and additional context that relates to the video transcription\",\n",
    "        \"relevancy_score\": \"score between 0 to 100 about relevancy of the image with respect to the transcript\",\n",
    "        \"necessity_to_include\": \"The absolute Necessity of the frame to be included in blog, between 0 to 100, based on the quality of the image and relevance with the transcript context. Only include relevant and extremely IMPORTANT IMAGES\"\n",
    "    }},\n",
    "    {{\n",
    "        ...\n",
    "    }}\n",
    "    ...\n",
    "]\n",
    "```\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result saved to: extracted_image_data/19.json\n",
      "Result saved to: extracted_image_data/20.json\n",
      "Result saved to: extracted_image_data/0.json\n",
      "Result saved to: extracted_image_data/3.json\n",
      "Result saved to: extracted_image_data/16.json\n",
      "Result saved to: extracted_image_data/15.json\n",
      "Result saved to: extracted_image_data/11.json\n",
      "Result saved to: extracted_image_data/17.json\n",
      "Result saved to: extracted_image_data/12.json\n",
      "Generated an exception: Expecting ',' delimiter: line 10 column 363 (char 1130)\n",
      "Result saved to: extracted_image_data/5.json\n",
      "Result saved to: extracted_image_data/8.json\n",
      "Result saved to: extracted_image_data/1.json\n",
      "Result saved to: extracted_image_data/14.json\n",
      "Result saved to: extracted_image_data/9.json\n",
      "Result saved to: extracted_image_data/10.json\n",
      "Result saved to: extracted_image_data/2.json\n",
      "Result saved to: extracted_image_data/13.json\n",
      "Result saved to: extracted_image_data/7.json\n",
      "Result saved to: extracted_image_data/18.json\n",
      "Result saved to: extracted_image_data/6.json\n"
     ]
    }
   ],
   "source": [
    "# Number of images to show per transcription\n",
    "\n",
    "video_url = 'https://youtu.be/3OamzN90kPg?si=TPOz9ny_SoKF35d4'\n",
    "transcript_segment_length = 20\n",
    "image_segment_length = 5\n",
    "concurrent_requests = 25\n",
    "\n",
    "frames_output_dir = \"./extracted_frames\"\n",
    "image_data_dir = \"extracted_image_data\"\n",
    "\n",
    "images_per_transcription = transcript_segment_length//image_segment_length\n",
    "\n",
    "\n",
    "##############\n",
    "\n",
    "# Download Video\n",
    "video_file = download_youtube_video(\n",
    "    video_url=video_url)\n",
    "\n",
    "# Extract audio from the downloaded video file\n",
    "extracted_audio = extract_audio_from_video(video_file_path=video_file)\n",
    "\n",
    "# Extract Frames from video\n",
    "image_paths = extract_frames_from_video(\n",
    "    video_path=video_file, output_folder=frames_output_dir, time_interval=4)\n",
    "\n",
    "# Transcribe audio\n",
    "transcription = transcribe_audio(\n",
    "    audio_file_path=extracted_audio, segment_len=transcript_segment_length)\n",
    "\n",
    "\n",
    "############\n",
    "\n",
    "# Get formatted length of the video\n",
    "with VideoFileClip(video_file) as video:\n",
    "    duration = int(round(video.duration))  # Convert to nearest whole number\n",
    "    formatted_video_duration = format_duration(duration)\n",
    "\n",
    "# Gather all the image paths\n",
    "image_paths_list = []\n",
    "\n",
    "for img in os.listdir(frames_output_dir):\n",
    "    image_paths_list.append(f\"{frames_output_dir}/{img}\")\n",
    "\n",
    "\n",
    "############\n",
    "\n",
    "\n",
    "def process_transcription(index, transcript, img_paths_to_print):\n",
    "    # Calculate timestamp\n",
    "    timestamp = get_segment_timestamp(segment_string=transcript)\n",
    "\n",
    "    # Construct the prompt for the GPT model\n",
    "    describe_images_prompt = PROMPT_TEMPLATE.format(\n",
    "        video_title=video_file,\n",
    "        segment_len=transcript_segment_length,\n",
    "        video_length=formatted_video_duration,\n",
    "        json_template=JSON_TEMPLATE,\n",
    "        image_paths=\"\\n\".join(img_paths_to_print),\n",
    "        timestamp=timestamp,\n",
    "        transcript_segment=transcript,\n",
    "    )\n",
    "\n",
    "    # Read image data and convert to base64\n",
    "    img_data_list = []\n",
    "    for img_path in img_paths_to_print:\n",
    "        with open(img_path, 'rb') as img_file:\n",
    "            img_data = img_file.read()\n",
    "            img_data_list.append(img_data)\n",
    "    \n",
    "    # Encode images to base64\n",
    "    encoded_images = convert_images_to_base64(img_data_list)\n",
    "\n",
    "    # Create the prompt\n",
    "    prompt = create_prompt(encoded_images=encoded_images, prompt_template=describe_images_prompt)\n",
    "\n",
    "    # Make the API call\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4-vision-preview\",\n",
    "        messages=prompt,\n",
    "        max_tokens=4096,\n",
    "    )\n",
    "    \n",
    "    # Extracting the model response\n",
    "    model_response = response.choices[0].message.content\n",
    "    extracted_json = extract_json_from_response(model_response=model_response)\n",
    "\n",
    "    # Save the result to a json file\n",
    "    output_folder = image_data_dir \n",
    "    os.makedirs(output_folder, exist_ok=True)  # Ensure the directory exists\n",
    "\n",
    "    file_path = f\"{output_folder}/{index}.txt\"\n",
    "    with open(file_path, 'w') as file:\n",
    "        file.write(model_response)\n",
    "\n",
    "    file_path = f\"{output_folder}/{index}.json\"\n",
    "    json_data = json.loads(extracted_json)\n",
    "    with open(file_path, 'w') as json_file:\n",
    "        json.dump(json_data, json_file, indent=4)\n",
    "\n",
    "    # Optionally return file path or other relevant data\n",
    "    return file_path\n",
    "\n",
    "\n",
    "# Use ThreadPoolExecutor to manage a pool of threads\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=concurrent_requests) as executor:\n",
    "    futures = []\n",
    "    \n",
    "    # Make a shallow copy of image_paths_list to avoid threading issues.\n",
    "    local_image_paths_list = image_paths_list[:]\n",
    "    \n",
    "    for i, transcript in enumerate(transcription):\n",
    "        # Determine the number of images to print for this transcription\n",
    "        if i == len(transcription) - 1:\n",
    "            img_paths_to_print = local_image_paths_list\n",
    "        else:\n",
    "            img_paths_to_print = local_image_paths_list[:images_per_transcription]\n",
    "        \n",
    "        # Update the image_paths_list by removing the printed images\n",
    "        local_image_paths_list = local_image_paths_list[len(img_paths_to_print):]\n",
    "        \n",
    "        # Submit the task to the executor\n",
    "        future = executor.submit(process_transcription, i, transcript, img_paths_to_print)\n",
    "        futures.append(future)\n",
    "\n",
    "    # Wait for all futures to complete\n",
    "    for future in concurrent.futures.as_completed(futures):\n",
    "        # You can check for the result or exception here if needed\n",
    "        try:\n",
    "            result = future.result()\n",
    "            # Log the result or store it if necessary\n",
    "            print(f'Result saved to: {result}')\n",
    "        except Exception as exc:\n",
    "            print(f'Generated an exception: {exc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of .json files: 21\n",
      "Number of .txt files: 21\n",
      "Number of Transcription Segments: 21\n"
     ]
    }
   ],
   "source": [
    "def count_files(directory):\n",
    "    json_count = 0\n",
    "    txt_count = 0\n",
    "\n",
    "    for file_name in os.listdir(directory):\n",
    "        if file_name.endswith('.json'):\n",
    "            json_count += 1\n",
    "        elif file_name.endswith('.txt'):\n",
    "            txt_count += 1\n",
    "\n",
    "    return json_count, txt_count\n",
    "\n",
    "directory_path = \"./extracted_image_data\"\n",
    "\n",
    "json_count, txt_count = count_files(directory_path)\n",
    "\n",
    "print(f\"Number of .json files: {json_count}\")\n",
    "print(f\"Number of .txt files: {txt_count}\")\n",
    "print(f\"Number of Transcription Segments: {len(transcription)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"00:00:00 - 00:00:20  Hey everyone, welcome back, and let's write some more neat code today. So today let's solve contains duplicate. This is another problem from the blind 75 list of questions we've been working on. So I like this problem because it's a good problem for beginners, but there's also multiple solutions to it that I'd like to go over in this video. So we're given an array of numbers.\", \"00:00:20 - 00:00:40 We want to return true if there's any value in that list of numbers that appears at least twice. So maybe it could appear three times or four times, right? Just at least twice. And we want to return false if there aren't any values that appear at least twice. Basically what that means is that every value in the array is distinct.\", \"00:00:40 - 00:01:00 So let's take a look at an example. We have one, two, three, and then we have one again. So of course this has duplicates, right? So we return true. And the easiest way we would be able to detect that is by brute forcing this. So given these numbers, the first thing we do is look at the first number.\", \"00:01:00 - 00:01:20 It's one. How do we know if this is a duplicate or not? Well, we'd have to compare it to every single number in the rest of the array. So that would be a big O of n time operation just to check if the first number is a duplicate or not. And then we'd have to do that for every number. Then we have to check, is the second number a duplicate?\", \"00:01:20 - 00:01:40 How do we know? We have to compare it to every other number. We do the same thing with the third one and the last one. And so since we're doing it for every number in the array, the overall time complexity is going to become n squared. And by the way, in this case, n is just the size of the input array. So the brute force solution is big O n squared time complexity.\", \"00:01:40 - 00:02:00 But the good thing is we don't need any extra memory. So the memory complexity is big O of one. It's definitely not a bad solution, but the question is, can we do better than that? And yes, we definitely can. A second approach that will help us is sorting. What happens if we took this array and we sorted it?\", \"00:02:00 - 00:02:20 It would look a little bit different. It would look like this. OK, but how does sorting help us? Well, let's think about it. If we sort the input, then any duplicates that do exist in the array, and clearly we see that two duplicates exist at the beginning of the array, they're going to be adjacent.\", \"00:02:20 - 00:02:40 So when we're trying to detect any duplicates in here, we only have to iterate through the array once. And as we do that, we're just going to be comparing two neighbors in the array, checking if they're duplicates. Next, we're going to shift our pointers to the next spot. Are these duplicates? Are these duplicates? Et cetera, et cetera, until we finish the entire array.\", \"00:02:40 - 00:03:00 In this case, we see that these two adjacent values are duplicates. So we can return true. And what's the time complexity of this? Well, the one pass is just going to be big O of n. But we know that sorting does take extra memory, or not extra memory, it does take extra time complexity. And that time complexity is n log n. So that's the bottleneck in this solution.\", \"00:03:00 - 00:03:20 But again, we don't need extra space if you don't count the space that's used by the sorting algorithm. So in this case, we do have a slightly better solution than brute force. But actually, if we use a little bit extra memory, and it's really a trade off, if we\", \"00:03:20 - 00:03:40 sacrifice space complexity, we can actually achieve better memory complexity. And let me show you how. So suppose we don't sort our input, we're given the default input. But we use extra memory, we use a hash set. But what exactly is a hash set going to do for us? It's going to allow us to insert elements into the hash set in big O of one time.\", \"00:03:40 - 00:04:00 But it's also going to allow us to check we can ask our hash map, does a certain value exist? We want to know, does this one exist in the hash map? Well, if we start at the beginning of the array, so far, nothing is in our hash map. So a one does not exist in our hash map.\", \"00:04:00 - 00:04:20 That means this one is not a duplicate. You can see that this is an improvement over the brute force previously, to determine if this was a duplicate, we had to check every other value in the array. This time, we don't. But after we have checked if this is a duplicate, we do have to add it to our hash set. Because later on, if we encounter a one, like over here, then we determine that this is\", \"00:04:20 - 00:04:40 a duplicate, because we know that there's already a one in our hash set. So next, we're going to check two, two is not a duplicate. Add it here is three a duplicate? Nope. Add it here. One. Is this a duplicate? Yep, there's a one over here. So we return true. This does contain duplicates.\", '00:04:40 - 00:05:00 And by the way, since each operation was just big O of one, we had to do that for every value in the input array. And we only had to scan through the list of inputs once, the time complexity is going to be big O of n. But the space complexity, we did have to sacrifice a little bit, we have to create a hash set. And the memory that that hash set will use could be up to the size of the input array,', \"00:05:00 - 00:05:20 which is n. So we do end up using extra memory. But that's not too bad. So this is about as efficient as we can get in terms of time complexity. So let's get into the code now. Okay, so now let's get into the code. So the first thing I'm going to do is create that hash set. In Python, you can do that just like this.\", \"00:05:20 - 00:05:40 It's just called a set. And then the simple thing is just going through every value in the input array nums. And before we end up adding it to our hash set, because remember, we want to add every one of these values to our hash set just like this. But before we even do that, we want to know, is n a duplicate?\", \"00:05:40 - 00:06:00 Does this value already exist in our hash set? And if it does, we know that our array contains duplicates. So we don't even have to continue through the rest of the array, we can immediately return true because we found a duplicate. But if it doesn't contain a duplicate, we're going to add that value, then iterate through\", \"00:06:00 - 00:06:20 the rest of the array of nums, and then the loop will exit and then we can return false to indicate that we did not find any duplicates in the array. Now let's run the code to make sure that it works. And on the left, you can see that yes, it does work and it is about as efficient as we can get. So I really hope that this was helpful.\", \"00:06:20 - 00:06:40 If it was, please like and subscribe. It supports the channel a lot. Consider checking out my Patreon where you can further support the channel and hopefully I'll see you pretty soon.\", '00:06:40 - 0.0:13.0:10.459991455078125 Thanks for watching.']\n"
     ]
    }
   ],
   "source": [
    "file_path = \"transcription.txt\"\n",
    "with open(file_path, 'w') as file:\n",
    "    file.write(\"\\n\".join(transcription))\n",
    "\n",
    "print(transcription)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "SYSTEM_PROMPT = \"\"\" You write Excellent Articles in markdown based on Youtube Transcripts and description of images from the videos.\n",
    "The aim generate \"companion guides\" for various tutorials in a more readable, skimmable, searchable format. \n",
    "\"\"\"\n",
    "\n",
    "USER_PROMPT = ''' You will be provided with transcription of segments from the video\n",
    "paired with JSON that contain\n",
    "- image_path: example \"./extracted_frames/0340.jpg\", the name of the image `0340` is the number of seconds from the begining of the video\n",
    "- summary: summary of the emage\n",
    "- relevancy_score: rough score of how relevent is the image with respect to transcription\n",
    "- necessity_to_include: necessity of the image to be included in the blog\n",
    "\n",
    "Below is the transcription between **{timestamp}**\n",
    "```\n",
    "{transcript_str}\n",
    "```\n",
    "\n",
    "For the above transcript, below is the description of intermediate frames fro mthe video:\n",
    "```json\n",
    "{formatted_json_string}\n",
    "```\n",
    "\n",
    "\n",
    "Based on the transcription string and the frame/image description json,\n",
    "\n",
    "Your task is to write a coprehensive segment of the article (which then be used to write the final article) including all the relevent details such as code snippets, links, images and titles in proper **markdown format**\n",
    "\n",
    "IMPORTANT 1: Keep in mind that this is just one segment of the entire Article so DO NOT conclude the artcile at the end. It will be combined with other segments to create the final article.\n",
    "\n",
    "IMPORTANT 2: ONLY INCLUDE Relevent and IMPORTANT IMAGES in the article and EXCLUDE redundant images and information\n",
    "\n",
    "Take DEEP Breath.\n",
    "Now write the segment of the article in markdown format:\n",
    "\n",
    "```markdown\n",
    "\n",
    "```\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_data_json = []\n",
    "for file_name in os.listdir(image_data_dir):\n",
    "    if file_name.endswith('.json'):\n",
    "        image_data_json.append(f\"{image_data_dir}/{file_name}\")\n",
    "\n",
    "print(len(image_data_dir))\n",
    "print(len(transcription))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " You will be provided with transcription of segments from the video\n",
      "paired with JSON that contain\n",
      "- image_path: example \"./extracted_frames/0340.jpg\", the name of the image `0340` is the number of seconds from the begining of the video\n",
      "- summary: summary of the emage\n",
      "- relevancy_score: rough score of how relevent is the image with respect to transcription\n",
      "- necessity_to_include: necessity of the image to be included in the blog\n",
      "\n",
      "Below is the transcription between **00:00:00 - 00:00:20**\n",
      "```\n",
      "00:00:00 - 00:00:20  Hey everyone, welcome back, and let's write some more neat code today. So today let's solve contains duplicate. This is another problem from the blind 75 list of questions we've been working on. So I like this problem because it's a good problem for beginners, but there's also multiple solutions to it that I'd like to go over in this video. So we're given an array of numbers.\n",
      "```\n",
      "\n",
      "For the above transcript, below is the description of intermediate frames fro mthe video:\n",
      "```json\n",
      "[\n",
      "    {\n",
      "        \"image_path\": \"./extracted_frames/0000.jpg\",\n",
      "        \"summary\": \"The image displays a screenshot of a Leetcode problem titled '217. Contains Duplicate'. The problem statement clarifies that the challenge is to determine whether an integer array named `nums` contains any duplicate values. The question is categorized as 'Easy' and is accompanied by three examples. Example 1 provides an input of `nums = [1,2,3,1]` and expects an output of `true`, indicating there is a duplicate. Example 2 has an input of `nums = [1,2,3,4]` and an output of `false`, signifying no duplicates. Example 3 inputs `nums = [1,1,1,3,3,4,3,2,4,2]`, also expecting an output of `true` due to the presence of duplicates. The image represents an important aspect of the video, introducing the problem that will be addressed in the following coding tutorial.\",\n",
      "        \"relevancy_score\": 95,\n",
      "        \"necessity_to_include\": 90\n",
      "    },\n",
      "    {\n",
      "        \"image_path\": \"./extracted_frames/0004.jpg\",\n",
      "        \"summary\": \"This image is a duplicate of the first one, displaying the same Leetcode problem statement and examples for '217. Contains Duplicate'. Since this frame adds no additional information beyond what was provided in the previous frame, it may be considered redundant for inclusion in the blog post.\",\n",
      "        \"relevancy_score\": 0,\n",
      "        \"necessity_to_include\": 0\n",
      "    },\n",
      "    {\n",
      "        \"image_path\": \"./extracted_frames/0008.jpg\",\n",
      "        \"summary\": \"The screenshot highlights the word 'Blind' written in blue ink, presumably by the video creator, over the Leetcode problem description for '217. Contains Duplicate'. This may indicate that the problem is part of a curated list commonly referred to as 'Blind 75', which is a collection of coding interview questions. While the highlight may serve to emphasize this association, the quality of the image is less than ideal for a professional blog post due to the handwriting overlay.\",\n",
      "        \"relevancy_score\": 70,\n",
      "        \"necessity_to_include\": 50\n",
      "    },\n",
      "    {\n",
      "        \"image_path\": \"./extracted_frames/0012.jpg\",\n",
      "        \"summary\": \"This image is identical to the first two, showing the Leetcode problem '217. Contains Duplicate'. Again, it features the same problem statement and examples. Including this frame would be superfluous since all necessary information has been captured in the initial frame provided for the article.\",\n",
      "        \"relevancy_score\": 0,\n",
      "        \"necessity_to_include\": 0\n",
      "    },\n",
      "    {\n",
      "        \"image_path\": \"./extracted_frames/0016.jpg\",\n",
      "        \"summary\": \"Here, the image shows the Leetcode problem '217. Contains Duplicate' with the problem title and statement underscored in blue ink. This highlighting might signify the importance of the problem statement, 'Given an integer array nums, return true if any value appears at least twice in the array, and return false if every element is distinct.' However, since this information has already been presented before, and the underlining may distract from the clarity of the text, this image might not be necessary for inclusion in the final article.\",\n",
      "        \"relevancy_score\": 50,\n",
      "        \"necessity_to_include\": 40\n",
      "    }\n",
      "]\n",
      "```\n",
      "\n",
      "\n",
      "Based on the transcription string and the frame/image description json,\n",
      "\n",
      "Your task is to write a coprehensive segment of the article (which then be used to write the final article) including all the relevent details such as code snippets, links, images and titles in proper **markdown format**\n",
      "\n",
      "IMPORTANT 1: Keep in mind that this just one segment of the entire Article so DO NOT conclude the artcile at the end. It will be combined with other segments to create the final article.\n",
      "\n",
      "IMPORTANT 2: ONLY INCLUDE Relevent and IMPORTANT IMAGES in the article and EXCLUDE redundant information\n",
      "\n",
      "Take DEEP Breath.\n",
      "Now write the segment of the article in markdown format:\n",
      "\n",
      "```markdown\n",
      "\n",
      "```\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "####\n",
    "\n",
    "image_data_json = []\n",
    "for file_name in os.listdir(image_data_dir):\n",
    "    if file_name.endswith('.json'):\n",
    "        image_data_json.append(f\"{image_data_dir}/{file_name}\")\n",
    "\n",
    "#####\n",
    "\n",
    "index = 0\n",
    "\n",
    "transcript_str = transcription[index]\n",
    "json_file_path = image_data_json[index]\n",
    "timestamp = get_segment_timestamp(segment_string=transcript_str)\n",
    "\n",
    "article_segments = \"./article_segments\"\n",
    "###\n",
    "\n",
    "with open(json_file_path, 'r') as file:\n",
    "    img_json_data = json.load(file)\n",
    "    formatted_json_string = json.dumps(img_json_data, indent=4)\n",
    "\n",
    "user_prompt = USER_PROMPT.format(timestamp=timestamp, transcript_str=transcript_str, formatted_json_string=formatted_json_string)\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4-1106-preview\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "        {\"role\": \"user\", \"content\": user_prompt},\n",
    "    ],\n",
    "    temperature=0.1,\n",
    ")\n",
    "\n",
    "model_response = completion.choices[0].message.content\n",
    "\n",
    "file_path = f\"{article_segments}/{index}.txt\"\n",
    "with open(file_path, 'w') as file:\n",
    "    file.write(model_response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result saved to: ./article_segments/12.txt\n",
      "Result saved to: ./article_segments/1.txt\n",
      "Result saved to: ./article_segments/2.txt\n",
      "Result saved to: ./article_segments/16.txt\n",
      "Result saved to: ./article_segments/17.txt\n",
      "Result saved to: ./article_segments/11.txt\n",
      "Result saved to: ./article_segments/4.txt\n",
      "Result saved to: ./article_segments/19.txt\n",
      "Result saved to: ./article_segments/15.txt\n",
      "Result saved to: ./article_segments/6.txt\n",
      "Result saved to: ./article_segments/8.txt\n",
      "Result saved to: ./article_segments/13.txt\n",
      "Result saved to: ./article_segments/0.txt\n",
      "Result saved to: ./article_segments/3.txt\n",
      "Result saved to: ./article_segments/5.txt\n",
      "Result saved to: ./article_segments/14.txt\n",
      "Result saved to: ./article_segments/10.txt\n",
      "Result saved to: ./article_segments/18.txt\n",
      "Result saved to: ./article_segments/7.txt\n",
      "Result saved to: ./article_segments/20.txt\n",
      "Result saved to: ./article_segments/9.txt\n"
     ]
    }
   ],
   "source": [
    "\n",
    "####\n",
    "\n",
    "image_data_json = []\n",
    "for file_name in os.listdir(image_data_dir):\n",
    "    if file_name.endswith('.json'):\n",
    "        image_data_json.append(f\"{image_data_dir}/{file_name}\")\n",
    "\n",
    "#####\n",
    "\n",
    "index = 0\n",
    "\n",
    "transcript_str = transcription[index]\n",
    "json_file_path = image_data_json[index]\n",
    "timestamp = get_segment_timestamp(segment_string=transcript_str)\n",
    "\n",
    "article_segments = \"./article_segments\"\n",
    "###\n",
    "\n",
    "max_workers = 30\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from itertools import zip_longest\n",
    "\n",
    "####\n",
    "\n",
    "def process_segment(index, transcript_str, json_file_path):\n",
    "    # If json_file_path is None, we assume there's no corresponding JSON file\n",
    "    if json_file_path:\n",
    "        with open(json_file_path, 'r') as file:\n",
    "            img_json_data = json.load(file)\n",
    "            formatted_json_string = json.dumps(img_json_data, indent=4)\n",
    "    else:\n",
    "        formatted_json_string = \"{}\"  # Empty JSON representation\n",
    "\n",
    "    timestamp = get_segment_timestamp(segment_string=transcript_str)\n",
    "    user_prompt = USER_PROMPT.format(timestamp=timestamp, transcript_str=transcript_str, formatted_json_string=formatted_json_string)\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4-1106-preview\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "            {\"role\": \"user\", \"content\": user_prompt},\n",
    "        ],\n",
    "        temperature=0.1,\n",
    "    )\n",
    "\n",
    "    model_response = completion.choices[0].message.content\n",
    "\n",
    "    os.makedirs(article_segments, exist_ok=True)  # Ensure the directory exists\n",
    "    file_path = f\"{article_segments}/{index}.txt\"\n",
    "    with open(file_path, 'w') as file:\n",
    "        file.write(model_response)\n",
    "    \n",
    "    return file_path\n",
    "\n",
    "\n",
    "# Use ThreadPoolExecutor to manage a pool of threads\n",
    "with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "    futures = []\n",
    "\n",
    "    # Iterate over the transcriptions and image data json paths\n",
    "    for index, (transcript_str, json_file_path) in enumerate(zip_longest(transcription, image_data_json, fillvalue=None)):\n",
    "        # Submit the task to the executor\n",
    "        future = executor.submit(process_segment, index, transcript_str, json_file_path)\n",
    "        futures.append(future)\n",
    "\n",
    "    # Wait for all futures to complete and handle results or exceptions\n",
    "    for future in as_completed(futures):\n",
    "        try:\n",
    "            result = future.result()\n",
    "            print(f'Result saved to: {result}')\n",
    "        except Exception as exc:\n",
    "            print(f'Generated an exception: {exc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Efficient Strategies for Solving the \"Contains Duplicate\" Problem in Arrays\n",
      "\n",
      "In the world of coding interviews and algorithm challenges, one frequently encountered question is the \"Contains Duplicate\" problem, which requires checking for the presence of duplicate values within an array. This task, while seemingly simple, opens up a discussion about various solutions and their associated time and space complexities. In this comprehensive guide, we will dissect multiple strategies for efficiently solving this problem, often highlighted in the \"Blind 75\" list of coding interview questions.\n",
      "\n",
      "## The \"Contains Duplicate\" Challenge\n",
      "\n",
      "LeetCode's Problem 217, \"Contains Duplicate,\" asks us to determine if any value appears at least twice in a given integer array `nums`. If a duplicate is present, the function should return `true`; otherwise, it should return `false`. This problem is an excellent test of basic data structure knowledge and algorithmic efficiency.\n",
      "\n",
      "![LeetCode Problem 217: Contains Duplicate](./extracted_frames/0000.jpg)\n",
      "\n",
      "### Examples to Consider\n",
      "\n",
      "- **Example 1**: `nums = [1,2,3,1]` should yield `true`, as the number 1 appears twice.\n",
      "- **Example 2**: For `nums = [1,2,3,4]`, the expected output is `false`, with all elements distinct.\n",
      "- **Example 3**: With `nums = [1,1,1,3,3,4,3,2,4,2]`, the correct output is `true`, given multiple duplicates.\n",
      "\n",
      "## Approaches to Detecting Duplicates\n",
      "\n",
      "There are various ways to solve this problem, each with its own trade-offs.\n",
      "\n",
      "### Brute Force Method\n",
      "\n",
      "The brute force approach involves comparing each element with every other element in the array, resulting in a time complexity of O(n^2), which is inefficient for large datasets.\n",
      "\n",
      "### Using Sorting\n",
      "\n",
      "An alternative to the brute force method is to sort the array and check each element against its neighbor, which improves time complexity but still relies on the sorting process, typically O(n log n).\n",
      "\n",
      "```python\n",
      "def containsDuplicate(nums):\n",
      "    nums.sort()\n",
      "    for i in range(1, len(nums)):\n",
      "        if nums[i] == nums[i-1]:\n",
      "            return True\n",
      "    return False\n",
      "```\n",
      "\n",
      "### Utilizing HashSets for Improved Efficiency\n",
      "\n",
      "A more sophisticated and commonly preferred solution involves using a hash set, which allows us to store elements and check for their existence in constant time, O(1). As such, the overall time complexity of this method is O(n), which is more favorable compared to sorting.\n",
      "\n",
      "```python\n",
      "class Solution:\n",
      "    def containsDuplicate(self, nums):\n",
      "        hashset = set()\n",
      "        for n in nums:\n",
      "            if n in hashset:\n",
      "                return True\n",
      "            hashset.add(n)\n",
      "        return False\n",
      "```\n",
      "\n",
      "![Python Code for containsDuplicate Method](./extracted_frames/0368.jpg)\n",
      "\n",
      "The space complexity for using a hash set is also O(n), as it may need to store each unique element from the array.\n",
      "\n",
      "## Advantages of the HashSet Approach\n",
      "\n",
      "### Immediate Duplicate Detection\n",
      "\n",
      "The `HashSet` approach is particularly efficient because it allows for instant detection of duplicates during iterationâ€”once a duplicate is found, the function can return `true` immediately without further processing.\n",
      "\n",
      "### Memory Complexity\n",
      "\n",
      "While a hash set introduces additional memory usage to store unique elements, this trade-off is justified by the significant improvement in time complexity compared to the brute force method.\n",
      "\n",
      "![Space Complexity O(1)](./extracted_frames/0104.jpg)\n",
      "\n",
      "### LeetCode Submission Results\n",
      "\n",
      "Submitting the solution to an online judge like LeetCode provides runtime and memory usage statistics, confirming the efficiency of the hash set approach.\n",
      "\n",
      "![LeetCode Submission Results](./extracted_frames/0376.jpg)\n",
      "\n",
      "## Conclusion\n",
      "\n",
      "In conclusion, when faced with the \"Contains Duplicate\" challenge, the hash set method stands out as an optimal solution in terms of both time and space complexity. By understanding and applying these efficient strategies, programmers can enhance their problem-solving skills and perform well in coding interviews and algorithm challenges.\n",
      "\n",
      "Stay tuned for more updates and tutorials on tackling common coding problems with efficient algorithms. For those interested in supporting further content, consider liking and subscribing, or check out my Patreon page.\n",
      "\n",
      "Remember, understanding these concepts not only helps in coding interviews but also forms the foundation for strong algorithmic thinking required in software development.\n"
     ]
    }
   ],
   "source": [
    "def read_files_in_directory(directory_path):\n",
    "    formatted_string = \"\"\n",
    "    for filename in os.listdir(directory_path):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            file_path = os.path.join(directory_path, filename)\n",
    "            with open(file_path, 'r') as file:\n",
    "                formatted_string += f\"*** Article Segment Number: {filename} ***\\n\\n\"\n",
    "                formatted_string += file.read() + \"\\n\\n\"\n",
    "    return formatted_string\n",
    "\n",
    "directory_path = \"./article_segments\"\n",
    "formatted_string = read_files_in_directory(directory_path)\n",
    "\n",
    "system_prompt = \"\"\"You are an excellent technical writer. Your task is to combine multiple small articles generated from 20 seconds of video each into a single comprehensive professional Article\n",
    "\"\"\"\n",
    "\n",
    "user_prompt = f\"\"\"Below are all the subarticles sequentially generated from 20 Second segments of the video\n",
    "\n",
    "Article Segments Start Here ->\n",
    "\n",
    "```\n",
    "{formatted_string}\n",
    "```\n",
    "\n",
    "<- Article Segments Ends Here\n",
    "\n",
    "Take a DEEP BREATH\n",
    "\n",
    "Include \n",
    "- relevent images\n",
    "- code snippets\n",
    "- links\n",
    "\n",
    "**IMPORTANT**\n",
    "**THE ARTICLE SHOULD BE AS DETAILED AS POSSIBLE**\n",
    "\n",
    "Now use ALL the article segments to write a SINGLE comprehensive and Detailed article COMBINING ALL the article segments in markdwon format:\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4-1106-preview\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt},\n",
    "    ],\n",
    "    temperature=0.85,\n",
    ")\n",
    "\n",
    "model_response = completion.choices[0].message.content\n",
    "\n",
    "print(model_response)\n",
    "\n",
    "file_path = \"final_article.md\"\n",
    "with open(file_path, 'w') as file:\n",
    "    file.write(model_response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
